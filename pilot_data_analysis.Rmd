---
title: "MB2 Pilot Analysis"
author: "The ManyBabies Analysis Team"
date: '`r format(Sys.time(), "%a %b %d %X %Y")`'
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: yes
editor_options: 
  chunk_output_type: inline
---

```{r libraries}
suppressMessages(library(here))
suppressMessages(library(jpeg))
suppressMessages(library(grid))
suppressMessages(library(lmerTest))
suppressMessages(library(car))

source(here::here("helper/common.R"))
source(here("helper/preprocessing_helper.R"))

knitr::opts_chunk$set(cache = TRUE, warn = FALSE, message = FALSE)
```


# Intro

Pilot data analysis for MB2.

We can re-preprocess all of our data, this is set not to evaluate by default. In order to do this, you will need to register with Eyelink to get their binary package and then install `edfR`.

```{r, eval=FALSE}
labs <- dir(here::here("pilot_data"))

for (lab in labs) {
  print(lab)
  source(here::here("pilot_data", lab, "import_scripts", "import.R"))
}

```


# File reading

```{r}
labs <- dir(here::here("pilot_data"))

d <- labs %>%
  map_df(function(lab) {
    aoi_data <- read_csv(here(paste0("pilot_data/",
                                     lab,"/processed_data/aoi_data.csv"))) 
    subjects <- read_csv(here(paste0("pilot_data/",
                                     lab,"/processed_data/subjects.csv"))) 
    trials <- read_csv(here(paste0("pilot_data/",
                                   lab,"/processed_data/trials.csv"))) 
    datasets <- read_csv(here(paste0("pilot_data/",
                                     lab,"/processed_data/datasets.csv")))
    
    left_join(aoi_data, subjects) %>%
      left_join(trials) %>%
      left_join(datasets) %>%
      select(lab_subject_id, lab_dataset_id, lab_trial_id, trial_id, 
             age, t, aoi, trial_num, error, experiment_num) %>%
      rename(subid = lab_subject_id, 
             lab = lab_dataset_id, 
             stimulus = lab_trial_id)
  })
```

# Exclusions

```{r}
d$experiment = ifelse(grepl("1a", d$experiment_num), "1a", "1b")

# exclude subject marked with any error and/or less than 8 trials
d <- d %>% 
  group_by(lab, subid, experiment) %>%
  mutate(error_subj = any(error)) %>%
      exclude_by(quo(error_subj), quiet=FALSE) 

# exclude trials under 32s (which are not complete trials)
# changed from 35s to 32 after pilot 1b because no_outcome
# trials are shorter
d <- ungroup(d) %>% 
  group_by(lab, trial_id, subid, experiment) %>%
  mutate(time_range = (max(t) - min(t))/1000) %>%
          exclude_by(quo(time_range <= 32), quiet=FALSE)

# print trial time ranges by lab
ungroup(d) %>%
  group_by(lab, experiment) %>% 
  summarise(shortest_trial=min(time_range),
            longest_trial=max(time_range)) %>%
  kable(digits=2)

# exclude subjects who did not complete 7/8 trials
d <- ungroup(d) %>% 
  group_by(lab, subid, experiment) %>%
  mutate(trials_completed = length(unique(trial_id))) %>%
           exclude_by(quo(trials_completed < 7),quiet=FALSE) %>% 
  ungroup(d) %>% 
  mutate(subid = paste0(subid, sep = " _ ", lab, trial_num)) 

```

# Analysis

Descriptives

```{r}
d %>%
  group_by(lab, subid) %>%
  summarise(age = mean(age)) %>%
  summarise(n = n(), 
            age = mean(age)/30.25) %>%
  kable(digits = 2)
  

```

Anticipation plot across all trials. 

```{r}
ms <- d %>% 
  group_by(t, trial_num, experiment_num) %>%
  summarise(target = mean(aoi == "target", na.rm=TRUE),
            distractor = mean(aoi == "distractor", na.rm=TRUE)) %>%
  gather(region, looking, target, distractor) 

ggplot(ms, aes(x = t, y = looking, col = region)) + 
  geom_line() + 
  geom_vline(xintercept = 120, col = "red", lty = 2) + 
  facet_grid(experiment_num ~ .) + 
  coord_cartesian(xlim = c(-4000+120, 4120)) #only consider the 4sec window before and after POD

```    

In the primary time period of interest

```{r}
ms <- d %>%
  group_by(t, experiment_num) %>%
  summarise(target = mean(aoi == "target", na.rm = TRUE),
            distractor = mean(aoi == "distractor", na.rm = TRUE)) %>%
  gather(region, looking, target, distractor) 
  
ggplot(ms, aes(x = t, y = looking, col = region)) +
  geom_point() + 
  xlim(-4000 + 120, 4000 + 120) + 
  geom_vline(xintercept = 120, col = "red", lty = 2) + 
  geom_text(x = -4000, y = .95, group = 1, col = "black", 
            label = "Anticipation", hjust = 0) + 
  geom_text(x = 200, y = .95, group = 1, col = "black", 
            label = "Reaction", hjust = 0) + 
  facet_grid(. ~ experiment_num)
```

Now, broken down by trial.
Summary across anticipation window.

```{r}
ms <- d %>%
  filter(t > -4000, t < 120) %>%
  group_by(lab, subid, trial_num, experiment_num) %>%
  summarise(target = mean(aoi == "target", na.rm = TRUE)) %>%
  group_by(trial_num, experiment_num) %>%
  langcog::multi_boot_standard(col = "target", na.rm = TRUE)


ggplot(ms, aes(x = trial_num, y = mean)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  geom_line() + 
  facet_grid(. ~ experiment_num)
```
  
   
Binned for cleaner curves

```{r}
ms <- d %>%
  mutate(block = ifelse(trial_num < 5, "Trials 1-4", "Trials 5-8")) %>%
  group_by(t, block, experiment_num) %>%
  summarise(target = mean(aoi == "target", na.rm = TRUE),
            distractor = mean(aoi == "distractor", na.rm = TRUE)) %>%
  gather(region, looking, target, distractor) 
  
ggplot(ms, aes(x = t, y = looking, col = region)) +
  geom_point() + 
  # geom_smooth(span = 2, se = FALSE) + 
  xlim(-4000 + 120, 4000 + 120) +
  geom_vline(xintercept = 120, col = "black", lty = 3) + 
  annotate("text", x = -3800, y = 1, col = "black",
            label = "Anticipation", hjust = 0) +
  annotate("text", x = 200, y = 1, col = "black", 
            label = "Reaction", hjust = 0) + 
  ggthemes::scale_color_solarized(name = "Area of Interest") + 
  xlab("Time (msec)") + 
  ylab("Proportion gaze in AOI") + 
  theme(legend.position = "bottom") + 
  facet_wrap(experiment_num~block)
```

And by lab:

```{r}
ms <- d %>%
  mutate(block = ifelse(trial_num < 5, 1, 2)) %>%
  group_by(t, lab, block, experiment_num) %>%
  summarise(target = mean(aoi == "target", na.rm = TRUE),
            distractor = mean(aoi == "distractor", na.rm = TRUE)) %>%
  gather(region, looking, target, distractor) 
  
ggplot(ms, aes(x = t, y = looking, col = region)) +
  geom_point() + 
  # geom_smooth(span = 2, se = FALSE) + 
  xlim(-4000 + 120, 4000 + 120) + 
  geom_vline(xintercept = 120, col = "red", lty = 2) +
  facet_grid(lab~block + experiment_num)
```

# Main analysis 1: First anticipatory look

Create a dataframe to identify the first look and see if the first look is >100ms

```{r}
# get time and location of first look (either target or distractor)

df_t_first_aoi <- d %>% 
  # for now only look at exp1, and at window between bear disappearing and point of disambiguation (+120 to account for time to react)
  filter(., t >= -4000+120, t <= 120) %>% 
  # create variable for AOI in order to exploit rle, which handles NaN's neatly
    mutate(aoi_recode = ifelse(aoi == "other", NA, aoi)) %>%
  group_by(subid, trial_num) %>% 
    # 4 consecutive timepoints looking at target or distractor is the first look
  mutate(first_look_aoi = rle(aoi_recode)$values[rle(aoi_recode)$lengths >= 4][1],
         first_look_t = t[sum(rle(aoi_recode)$lengths[0:(which.max(rle(aoi_recode)$lengths >= 4)-1)])+1]) %>% 
  ungroup()
  

    
# short df with first looks to check
first_looks_df <- df_t_first_aoi %>% 
  #select(subid, trial_num, first_look_aoi, first_look_t, age, experiment_num) %>% 
  group_by(subid, trial_num, experiment_num) %>%
  summarize(aoi = unique(first_look_aoi))

```

Number of first look in differnet experiments, looks like pilot 1b outcome and no outcome conditions have similiar number of first look

Note that NA represents trials where the kid only looked at other places (not target/distractor) during the whole anticipatory window between -3880 to +120 ms

I checked online, didn't find any concensus of how to analyze the "other" looking. Different people have different decisions on how to treat the "other" looking in the analyses. 

I suggest removing "NA (other)" in the following analyses, as I think that looking at "distractor" and "other" are two different concepts. Theortically, we are interested in understanding whether kids looked at target more than distractor and we may not want to include the time when kids were bored and didn't pay attention to trials/simply did not understand the task. In addition, the number of cases when kids only looked at "other" is low across experiments, so we are good.
```{r}
first_looks_df %>% 
  group_by(aoi, experiment_num) %>% 
  count()
```


## Data visualization across different test trials

```{r}
ggplot(first_looks_df, aes(x = aoi)) + 
  geom_bar() + 
  facet_wrap(experiment_num~trial_num, ncol = 4)
```

## Descriptive stats
Note that the following analyses removed NA (i.e., when kids looked at other all the time during the anticipatory window between -3880ms to +120ms)

Mean and sd of first look location in different trials. The means of all trials are above 50%

```{r}
mean_sd_aoi <- first_looks_df %>% 
  filter(!is.na(aoi)) %>% 
  mutate(aoi_dummy = ifelse(aoi == "target", 1, 0)) %>% 
  group_by(trial_num, experiment_num) %>% 
  summarize(number_of_kids_each_trial = n(),
            mean(aoi_dummy),
            sd(aoi_dummy))

```

Data visualization

```{r}
ggplot(mean_sd_aoi, aes(x = trial_num, y = `mean(aoi_dummy)`)) +
  geom_line()+
  facet_grid(.~experiment_num)
```

## Mixed-level analysis: First look location

Pilot 1a: kids looked at target less over time. But generally speaking, they still looked at targat significantly more than distracter
```{r first_look_analysis, results = "verbatim"}
first_looks_df_1a <- first_looks_df %>% 
  filter(experiment_num == "pilot_1a", !is.na(aoi)) %>% 
  mutate(aoi_dummy = ifelse(aoi == "target", 1, 0))
  
first_look_1a <- glmer(aoi_dummy ~ trial_num + (1|subid), data = first_looks_df_1a, family = "binomial")

summary(first_look_1a)
```

Pilot 1a (trial 1 to 4) vs Pilot 1b_outcome: no difference between 1a and 1b_outcome in the first look at the target 
```{r}
first_looks_df_1a_1b <- first_looks_df %>% 
  filter(experiment_num != "pilot_1b_no_outcome", 
         trial_num < 5,
         !is.na(aoi)) %>% 
  mutate(aoi_dummy = ifelse(aoi == "target", 1, 0))
  
first_look_1a_1b <- glmer(aoi_dummy ~ trial_num + experiment_num + (1|subid), data = first_looks_df_1a_1b, family = "binomial")

summary(first_look_1a_1b)
```

Pilot 1b_outcome vs Pilot 1b_no_outcome, no difference between 1a and 1b in the first look at the target, but need to interpret the results with caution because we have so little data and even the intercept is not significant
```{r}
first_looks_df_1b <- first_looks_df %>% 
  filter(experiment_num != "pilot_1a", 
         !is.na(aoi)) %>% 
  mutate(aoi_dummy = ifelse(aoi == "target", 1, 0))
  
first_look_1b <- glmer(aoi_dummy ~ trial_num + experiment_num + (1|subid), data = first_looks_df_1b, family = "binomial")

summary(first_look_1b)
```


# Main analysis 2: Differential analysis 
This analysis explores whether kids looked at the target more than distractor during anticipatory period. 

## Data visualization across different test trials
```{r}
ms_proportion_trials <- d %>%
  group_by(t, trial_num, experiment_num) %>%
  summarise(target = mean(aoi == "target", na.rm = TRUE),
            distractor = mean(aoi == "distractor", na.rm = TRUE)) %>%
  mutate(proportion_to_target = target / (target + distractor)) %>% 
  filter(t >= -2000+120 & t <= 2120)


ggplot(ms_proportion_trials, 
       aes(x = t, y = proportion_to_target)) +
  geom_point(alpha = 0.3) + 
  ylim(0,1) + 
  # geom_smooth(span = 2, se = FALSE) + 
  xlim(-2000+120, 2120) + 
  geom_vline(xintercept = 120, col = "red", lty = 2) + 
  geom_text(x = -2000+120, y = .95, group = 1, col = "black", 
            label = "Anticipation", hjust = 0 ) + 
  geom_text(x = 200, y = .95, group = 1, col = "black", 
            label = "Reaction", hjust = 0 )+
  facet_wrap(experiment_num~trial_num, ncol = 4)   
```

Create data-set for the mixed-level analysis
```{r}
ms_proportion_trials <- d %>%
  filter (t >= -4000+120 & t <= 120) %>% 
  group_by(experiment_num, trial_num, subid, lab) %>%
  summarise(mean_target = mean(aoi == "target", na.rm = TRUE),
            sem_target = sd(aoi == "target", na.rm = TRUE) / sqrt(length(aoi == "target")),
            mean_distractor = mean(aoi == "distractor", na.rm = TRUE), 
            sem_distractor = sd(aoi == "distractor", na.rm = TRUE) / sqrt(length(aoi == "distractor")),
            up_ci_target = mean_target + (sem_target * 1.96),
            low_ci_target = mean_target - (sem_target * 1.96),
            up_ci_distractor = mean_distractor + (sem_distractor * 1.96),
            low_ci_distractor = mean_distractor - (sem_distractor * 1.96)) %>% 
  mutate(proportion_to_target = mean_target / (mean_target + mean_distractor))
```

## Logistic Mixed-level analysis during the pre-disambiguation period (-1880 to 120 window)

### compare pilot 1a (trial 1 to 4) and pilot 1b outcome
```{r mixed-level logistic analysis}
d_2120_window_1a_1b_outcome <- d %>% 
  filter(t >= -2000+120, t <= 120, 
         experiment_num %in% c("pilot_1a", "pilot_1b_outcome"), 
         trial_num <5,
         aoi != "other") %>%
  mutate(aoi_dummy = case_when(aoi == "target" ~ 1, 
                               aoi == "distractor" ~ 0))

ls_target_2120_1a_1b_outcome <- glmer(aoi_dummy ~ trial_num + experiment_num + (trial_num|subid), 
                                     data = d_2120_window_1a_1b_outcome, family = "binomial")
summary(ls_target_2120_1a_1b_outcome)
```

### only focus on pilot 1b non outcome
```{r}
d_2120_window_1b_no_outcome <- d %>% 
  filter(t >= -2000+120, t <= 120, 
         experiment_num == "pilot_1b_no_outcome",
         aoi != "other") %>%
  mutate(aoi_dummy = case_when(aoi == "target" ~ 1, 
                               aoi == "distractor" ~ 0))

ls_target_2120_1b_no_outcome <- glmer(aoi_dummy ~ trial_num + (trial_num|subid), 
                                     data = d_2120_window_1b_no_outcome, family = "binomial")
summary(ls_target_2120_1b_no_outcome)
```

## Logistic Mixed-level analysis during the poste-disambiguation period (0 to 2120), compare pilot 1b outcome vs no-outcome
```{r}
d_2120_window_1b <- d %>% 
  filter(t >= 0, t <= 2120, 
         experiment_num != "pilot_1a",
         aoi != "other") %>%
  mutate(aoi_dummy = case_when(aoi == "target" ~ 1, 
                               aoi == "distractor" ~ 0))

ls_target_2120_1b <- glmer(aoi_dummy ~ trial_num + experiment_num + (trial_num|subid), 
                                     data = d_2120_window_1b, family = "binomial")
summary(ls_target_2120_1b)
```

```{r prop looking, eval = FALSE}

# df_pilot_1a_b_trial1to4 <- ms_proportion_trials %>% filter(experiment_num != "pilot_1b_no_outcome", trial_num <5)
# 
# 
# prop_model_1a_b_trial_1to4 <- lmer(proportion_to_target ~ experiment_num + trial_num + (1|subid), data = df_pilot_1a_b_trial1to4)
# summary(prop_model_1a_b_trial_1to4) 

## Linear hypothesis test to see if the intercept of the prop_model is signficantly higher than chance level (0.5)
 
# linearHypothesis(prop_model, "(Intercept) = 0.5")

# the linear hypothesis test is also confirmed by calculating the z score of this intercept, I used the coefficient and the sd of the random intercept
# z_intercept <- 0.7525/0.066 #much higher than 1.96
```
